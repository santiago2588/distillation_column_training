{
  "documentation": {
    "overview": "Documentation for answer schema: Each session (SE01, SE02, etc.) contains multiple exercises",
    "exercise_structure": [
      "answers: Object containing expected outputs for each part",
      "hints: Array of hints that guide students when they make errors"
    ],
    "schema_conventions": {
      "tensors": {
        "value": "The expected tensor values",
        "dtype": "The expected tensor data type (e.g. torch.float32)",
        "shape": "(Optional) The expected tensor shape",
        "value_range": "(Optional) min_val/max_val for random tensors, acceptable value range"
      },
      "scalar_values": {
        "expected": "The expected numerical value",
        "tolerance": "How much the student's answer can deviate from expected"
      },
      "boolean_checks": {
        "expected": "true/false with the expected outcome",
        "tolerance": "(Optional) For numerical comparison before boolean conversion"
      },
      "function_validation": {
        "test_cases": "Array of input/expected pairs to test the function",
        "tolerance": "How much outputs can deviate from expected values"
      }
    }
  },
  "SE01": {
    "exercise_1": {
      "answers": {
        "scalar_tensor": {
          "value": 42,
          "dtype": "torch.int64"
        },
        "float_tensor": {
          "value": 3.14,
          "dtype": "torch.float32"
        }
      },
      "hints": [
        "Remember to use torch.tensor() and specify dtype=torch.float32 for the float tensor",
        "The scalar tensor should be created with just the value 42"
      ]
    },
    "exercise_2": {
      "answers": {
        "random_tensor": {
          "shape": [3, 3],
          "dtype": "torch.int64",
          "min_val": 1,
          "max_val": 10
        },
        "identity_matrix": {
          "shape": [3, 3],
          "dtype": "torch.float32",
          "diagonal": 1.0
        },
        "spaced_tensor": {
          "shape": [5],
          "dtype": "torch.float32",
          "min_val": 0.0,
          "max_val": 1.0
        },
        "zero_tensor": {
          "shape": [2, 3],
          "dtype": "torch.float32",
          "value": 0.0
        }
      },
      "hints": [
        "Use torch.randint() for random integers",
        "Use torch.eye() for identity matrix",
        "Use torch.linspace() for evenly spaced numbers",
        "Use torch.zeros() for zero tensor"
      ]
    },
    "exercise_3": {
      "answers": {
        "position_2_3": {
          "value": 12,
          "dtype": "torch.int64"
        },
        "second_row": {
          "value": [5, 6, 7, 8],
          "dtype": "torch.int64"
        },
        "last_column": {
          "value": [4, 8, 12, 16],
          "dtype": "torch.int64"
        },
        "bottom_right": {
          "value": [
            [11, 12],
            [15, 16]
          ],
          "dtype": "torch.int64"
        },
        "even_elements": {
          "value": [2, 4],
          "dtype": "torch.int64"
        },
        "all_corners": {
          "value": [
            [1, 4],
            [13, 16]
          ],
          "dtype": "torch.int64"
        },
        "middle_block": {
          "value": [
            [6, 7],
            [10, 11]
          ],
          "dtype": "torch.int64"
        }
      },
      "hints": [
        "Use index [2,3] for position_2_3",
        "Use index [1,:] for second row",
        "Use index [:,3] for last column",
        "Use index [2:,2:] for bottom right",
        "Use index [0,1::2] for even elements",
        "Use [...,[0,-1]] for corners",
        "Use [1:3,1:3] for middle block"
      ]
    },
    "exercise_4": {
      "answers": {
        "addition": {
          "value": [
            [6, 8],
            [10, 12]
          ],
          "dtype": "torch.int64"
        },
        "multiplication": {
          "value": [
            [5, 12],
            [21, 32]
          ],
          "dtype": "torch.int64"
        },
        "matrix_mult": {
          "value": [
            [19, 22],
            [43, 50]
          ],
          "dtype": "torch.int64"
        },
        "sqrt_a": {
          "value": [
            [1.0, 1.4142],
            [1.7321, 2.0]
          ],
          "dtype": "torch.float32"
        }
      },
      "hints": [
        "Use + for addition",
        "Use * for element-wise multiplication",
        "Use @ for matrix multiplication",
        "Use torch.sqrt() and convert to float first"
      ]
    },
    "exercise_5": {
      "answers": {
        "matrix_mult": {
          "value": [
            [7, 10],
            [15, 22]
          ],
          "dtype": "torch.float32"
        },
        "transpose": {
          "value": [
            [1, 3],
            [2, 4]
          ],
          "dtype": "torch.float32"
        },
        "determinant": {
          "value": -2.0,
          "dtype": "torch.float32"
        },
        "inverse": {
          "value": [
            [-2.0, 1.0],
            [1.5, -0.5]
          ],
          "dtype": "torch.float32"
        }
      },
      "hints": [
        "Use @ or matmul() for matrix multiplication",
        "Use .T for transpose",
        "Use torch.det() for determinant",
        "Use torch.inverse() for matrix inverse"
      ]
    },
    "exercise_6": {
      "answers": {
        "broadcast_add": {
          "value": [
            [3, 4],
            [5, 6]
          ],
          "dtype": "torch.int64"
        },
        "broadcast_mult": {
          "value": [
            [2, 4],
            [6, 8]
          ],
          "dtype": "torch.int64"
        },
        "row_add": {
          "value": [
            [2, 3],
            [4, 5]
          ],
          "dtype": "torch.int64"
        },
        "col_mult": {
          "value": [
            [2, 4],
            [9, 12]
          ],
          "dtype": "torch.int64"
        },
        "batch_scale": {
          "value": [
            [
              [2, 4],
              [6, 8]
            ],
            [
              [10, 12],
              [14, 16]
            ]
          ],
          "dtype": "torch.int64"
        }
      },
      "hints": [
        "Scalar broadcasting adds/multiplies the scalar to all elements",
        "Row broadcasting applies operation across columns",
        "Column broadcasting applies operation across rows",
        "Batch broadcasting applies operation to all batches",
        "Check shapes with .shape after broadcasting"
      ]
    },
    "exercise_7": {
      "answers": {
        "reshaped": {
          "value": [
            [1, 2],
            [3, 4],
            [5, 6]
          ],
          "shape": [3, 2],
          "dtype": "torch.int64"
        },
        "expanded": {
          "value": [[1], [1], [1]],
          "shape": [3, 1],
          "dtype": "torch.float32"
        },
        "broadcast_ready": {
          "value": [[1], [2], [3]],
          "shape": [3, 1],
          "dtype": "torch.int64"
        }
      },
      "hints": [
        "Use reshape(rows, cols) to reshape flat tensor",
        "Use expand() to repeat values without copying",
        "Use reshape(-1, 1) to make column vector",
        "Test broadcasting with a dummy matrix"
      ]
    },
    "exercise_8": {
      "answers": {
        "grad_value": {
          "value": 39.0,
          "dtype": "torch.float32"
        },
        "requires_grad": {
          "value": true
        }
      },
      "hints": [
        "Set requires_grad=True when creating tensor",
        "Use backward() to compute gradients",
        "Access gradients with .grad attribute",
        "Derivative of y = 3x^3 + 2x^2 - 5x + 1 is dy/dx = 9x^2 + 4x - 5",
        "At x=2: dy/dx = 9(4) + 4(2) - 5 = 36 + 8 - 5 = 39"
      ]
    },
    "exercise_9": {
      "answers": {
        "px_tensor": {
          "shape": [6000],
          "dtype": "torch.float64",
          "column": "Px"
        },
        "py_tensor": {
          "shape": [6000],
          "dtype": "torch.float64",
          "column": "Py"
        },
        "pos_tensor": {
          "shape": [6000, 3],
          "dtype": "torch.float64",
          "columns": ["Px", "Py", "Pz"]
        },
        "all_data": {
          "shape": [6000, 6],
          "dtype": "torch.float32"
        }
      },
      "hints": [
        "Use df.column_name.values to get NumPy array",
        "Use torch.tensor() to convert to tensor",
        "Use df[['col1', 'col2']].values for multiple columns",
        "Use .to(device) to move tensor to GPU",
        "Check tensor shapes with .shape attribute"
      ]
    }
  },
  "SE02": {
    "exercise_1": {
      "answers": {
        "sigmoid": {
          "test_cases": [
            {
              "input": [0.0],
              "expected": 0.5
            },
            {
              "input": [1.0],
              "expected": 0.7311
            },
            {
              "input": [2.0],
              "expected": 0.8808
            },
            {
              "input": [-1.0],
              "expected": 0.2689
            },
            {
              "input": [-2.0],
              "expected": 0.1192
            }
          ],
          "tolerance": 1e-4
        },
        "neuron_input_size": {
          "expected": 2,
          "tolerance": 0
        },
        "has_bias": {
          "expected": true
        },
        "is_parameterized": {
          "expected": true
        }
      },
      "hints": [
        "The sigmoid function is defined as 1 / (1 + e^(-x))",
        "Use torch.exp(-x) for the exponential part",
        "For the neuron class, remember to use torch.nn.Parameter for weights and bias",
        "The forward method should compute the dot product between weights and input, add bias, then apply activation",
        "For the output test, given input [1.0, 2.0] with weights [1.0, 1.0] and bias 0.5, the result should be close to 0.97",
        "For the neuron class, initialize weights with torch.randn(input_features) to get random values",
        "Make weights and bias learnable by wrapping them with torch.nn.Parameter",
        "Make sure your neuron has the correct number of input features (weights)"
      ]
    },
    "exercise_2": {
      "answers": {
        "f_to_c": {
          "test_cases": [
            {
              "input": [32.0],
              "expected": 0.0
            },
            {
              "input": [212.0],
              "expected": 100.0
            },
            {
              "input": [68.0],
              "expected": 20.0
            }
          ],
          "tolerance": 1e-4
        },
        "X_shape": {
          "shape": [23, 1],
          "tolerance": 0
        },
        "y_shape": {
          "shape": [23, 1],
          "tolerance": 0
        },
        "X_mean": {
          "expected": 20.8696,
          "tolerance": 1e-4
        },
        "X_std": {
          "expected": 3.9206,
          "tolerance": 1e-4
        },
        "n_distress_cases": {
          "expected": 6.0,
          "tolerance": 0
        },
        "data_clipped": {
          "expected": true
        },
        "train_test_split_ratio": {
          "expected": true
        },
        "tensors_created": {
          "expected": true
        }
      },
      "hints": [
        "The Fahrenheit to Celsius conversion formula is: C = (F - 32) * 5 / 9",
        "Use the clip() method to cap n_distressed values at 1.0",
        "Convert temperature values to PyTorch tensors with .float() and reshape with .view(-1, 1)",
        "Similarly convert n_distressed values and reshape to match temperature shape",
        "Calculate mean with X.mean() and standard deviation with X.std()",
        "Normalize using the formula: (X - X_mean) / X_std",
        "Count distress cases by summing the target tensor with y.sum().item()",
        "Make sure to split the data with approximately 80% for training"
      ]
    },
    "exercise_3": {
      "answers": {
        "mse_loss": {
          "test_cases": [
            {
              "input": [
                {
                  "predictions": [[0.0], [0.5], [1.0]],
                  "targets": [[0.0], [0.0], [1.0]]
                }
              ],
              "expected": 0.0833
            },
            {
              "input": [
                {
                  "predictions": [[0.3], [0.7]],
                  "targets": [[0.0], [1.0]]
                }
              ],
              "expected": 0.09
            },
            {
              "input": [
                {
                  "predictions": [[0.0], [0.0]],
                  "targets": [[1.0], [1.0]]
                }
              ],
              "expected": 1.0
            }
          ],
          "tolerance": 1e-3
        }
      },
      "hints": [
        "Mean Squared Error is calculated as the average of squared differences: mean((predictions - targets)**2)",
        "Use squared_diff = (predictions - targets) ** 2 to calculate the squared differences",
        "Use squared_diff.mean() to get the average",
        "To verify your implementation, compare with PyTorch's nn.MSELoss()",
        "Loop through each input to get predictions from your model",
        "Forward pass: model(X_normalized[i]) for each data point"
      ]
    },
    "exercise_4": {
      "answers": {
        "training_convergence": {
          "expected": true,
          "tolerance": 0
        },
        "final_loss": {
          "max_val": 0.15,
          "min_val": 0.0
        },
        "negative_weight": {
          "expected": true,
          "tolerance": 0
        }
      },
      "hints": [
        "In the backward pass, call loss.backward() to compute gradients",
        "Update parameters using weight -= learning_rate * weight.grad",
        "Remember to zero gradients with weight.grad.zero_() after each update",
        "Use with torch.no_grad(): when updating parameters to prevent tracking computations",
        "For the O-ring data, you should see the weight become negative (indicating higher failure at lower temperatures)",
        "Monitor the loss over time - it should decrease and eventually stabilize"
      ]
    },
    "exercise_5": {
      "answers": {
        "challenger_failure_prob": {
          "expected": 0.9,
          "tolerance": 0.15
        },
        "recommendation": {
          "expected": true
        },
        "relative_risk_factor": {
          "expected": true
        }
      },
      "hints": [
        "Remember to use the same normalization (subtract X_mean and divide by X_std) for the Challenger temperature",
        "Use model(challenger_tensor) to get the failure probability prediction",
        "The failure probability should be very high (over 0.7) for the cold launch temperature",
        "Compare with a typical 'safe' temperature to see how much higher the risk is",
        "Given the high probability, the recommendation should be to NOT launch",
        "The relative risk should show that failure is many times more likely at the cold launch temperature",
        "Make sure to use with torch.no_grad() when making predictions with a trained model",
        "Normalize the challenger temperature using the same mean and standard deviation as the training data",
        "To calculate relative risk, divide the probability of failure at the challenger temperature by the probability at a normal temperature"
      ]
    },
    "exercise_6": {
      "answers": {
        "test_accuracy": {
          "expected": 0.8,
          "tolerance": 0.2
        },
        "test_precision": {
          "expected": 0.7,
          "tolerance": 0.3
        },
        "test_recall": {
          "expected": 0.7,
          "tolerance": 0.3
        },
        "test_f1": {
          "expected": 0.7,
          "tolerance": 0.3
        }
      },
      "hints": [
        "To evaluate on the test set, apply the same prediction process to X_test",
        "Calculate accuracy by comparing binary predictions (threshold 0.5) with actual values",
        "Accuracy is the ratio of correct predictions to total predictions",
        "True positives (TP) are cases where both prediction and actual are 1",
        "False positives (FP) are cases where prediction is 1 but actual is 0",
        "False negatives (FN) are cases where prediction is 0 but actual is 1",
        "Precision = TP / (TP + FP) - what fraction of positive predictions were correct",
        "Recall = TP / (TP + FN) - what fraction of actual positives were correctly identified",
        "F1 score = 2 * (precision * recall) / (precision + recall)",
        "Be careful with division by zero when calculating precision, recall, and F1 score",
        "Use binary_predictions = (test_predictions > 0.5).float() to convert probabilities to binary values",
        "Visualize the test predictions to better understand model performance"
      ]
    }
  },
  "SE03": {
    "exercise_1": {
      "answers": {
        "X_train_tensor": {
          "dtype": "torch.float32"
        },
        "y_train_tensor": {
          "dtype": "torch.float32"
        },
        "X_train_scaled": {
          "min_val": 0.0,
          "max_val": 1.0,
          "dtype": "torch.float32"
        },
        "y_train_scaled": {
          "min_val": 0.0,
          "max_val": 1.0,
          "dtype": "torch.float32"
        },
        "scale_range_min": {
          "expected": 0.0,
          "tolerance": 0
        },
        "scale_range_max": {
          "expected": 1.0,
          "tolerance": 0
        }
      },
      "hints": [
        "Use torch.tensor() to convert the DataFrame values to PyTorch tensors with dtype=torch.float32",
        "Create a CustomScaler with method='minmax' for proper normalization",
        "Remember to fit the scaler on the training data only",
        "Apply the transform method to normalize the data",
        "Check that the normalized data is in the range [0, 1]"
      ]
    },
    "exercise_2": {
      "answers": {
        "model": {
          "architecture": "Module"
        },
        "input_layer_size": {
          "expected": 6
        },
        "output_layer_size": {
          "expected": 5
        },
        "activation_type": {
          "expected_type": "ReLU"
        },
        "fc1_weight_stats": {
          "mean_near_zero": true,
          "std_range": [0.1, 0.5]
        },
        "fc2_weight_stats": {
          "mean_near_zero": true,
          "std_range": [0.1, 0.5]
        },
        "fc1_bias_stats": {
          "mean_near_zero": true,
          "std_range": [0.0, 1e-5]
        },
        "fc2_bias_stats": {
          "mean_near_zero": true,
          "std_range": [0.0, 1e-5]
        }
      },
      "hints": [
        "Initialize the parent class with super().__init__()",
        "Use torch.nn.Linear for fully connected layers with appropriate input and output sizes",
        "Use torch.nn.ReLU() for the activation function",
        "Use a smaller network (32 hidden neurons) to avoid overfitting",
        "Initialize the first layer weights with torch.nn.init.kaiming_uniform_ which is appropriate for ReLU activations",
        "Use torch.nn.init.xavier_uniform_ for the output layer weights which works well with linear outputs",
        "Initialize all biases to zero with torch.nn.init.zeros_",
        "Kaiming initialization should produce weights with mean near zero and std between 0.1-0.5",
        "Xavier initialization should also have mean near zero but with appropriate variance for the layer size",
        "The final layer should not have an activation function as this is a regression task"
      ]
    },
    "exercise_3": {
      "answers": {
        "optimizer_type": {
          "expected_type": "Adam"
        },
        "learning_rate": {
          "min_val": 0.0001,
          "max_val": 0.1
        },
        "loss_function_type": {
          "expected_type": "MSELoss"
        }
      },
      "hints": [
        "Use torch.optim.Adam with params=model.parameters() and lr=0.001",
        "Use torch.nn.MSELoss() for the loss function",
        "Store both optimizer and loss function as attributes of the model for easy access",
        "The learning rate is passed as a parameter to the optimizer"
      ]
    },
    "exercise_4": {
      "answers": {
        "train_losses": {
          "min_val": 0.0,
          "max_val": 0.03
        },
        "val_losses": {
          "min_val": 0.0,
          "max_val": 0.03
        },
        "loss_trend": {
          "expected": true
        },
        "overfit_check": {
          "expected": true
        }
      },
      "hints": [
        "Call model.train() to put the model in training mode",
        "Zero the gradients with model.optimizer.zero_grad() before each forward pass",
        "Forward pass: compute predictions with model(train_features)",
        "Compute loss with model.loss_function(predictions, train_targets)",
        "Backward pass: compute gradients with loss.backward()",
        "Update weights with model.optimizer.step()",
        "Use model.eval() and torch.no_grad() when computing validation loss"
      ]
    },
    "exercise_5": {
      "answers": {
        "test_loss": {
          "min_val": 0.0,
          "max_val": 0.03
        },
        "r2_score": {
          "min_val": 0.7,
          "max_val": 1.0
        },
        "predictions_shape": {
          "expected": true
        },
        "values_match": {
          "expected": true
        }
      },
      "hints": [
        "Put the model in evaluation mode with model.eval()",
        "Use torch.no_grad() to disable gradient tracking during evaluation",
        "Get predictions with model(X_test_scaled)",
        "Calculate loss with model.loss_function(test_predictions, y_test_scaled)",
        "Use y_scaler.inverse_transform() to convert predictions and targets back to original scale",
        "Calculate R-squared score with utils.ml.r2_score(test_targets_original, test_predictions_original)"
      ]
    }
  },
  "SE03P": {
    "exercise_6": {
      "answers": {
        "x_train": {
          "dtype": "torch.float32",
          "shape": [5000, 1]
        },
        "y_train": {
          "dtype": "torch.float32",
          "shape": [5000, 1]
        },
        "t_train": {
          "dtype": "torch.float32",
          "shape": [5000, 1]
        },
        "u_train": {
          "dtype": "torch.float32",
          "shape": [5000, 1]
        },
        "v_train": {
          "dtype": "torch.float32",
          "shape": [5000, 1]
        },
        "data_shape": {
          "min_val": 1,
          "max_val": 10000
        }
      },
      "hints": [
        "Make sure to extract the x and y coordinates correctly from x_star",
        "Use np.tile to repeat coordinates across timesteps",
        "Remember to flatten arrays before creating tensors",
        "Use torch.tensor() with dtype=torch.float32 to create tensors",
        "Check that all tensors have the same number of samples"
      ]
    },
    "exercise_7": {
      "answers": {
        "model": {
          "architecture": "Module"
        },
        "hidden_size": {
          "min_val": 10,
          "max_val": 100
        },
        "input_size": {
          "expected": 3
        },
        "output_size": {
          "expected": 3
        },
        "num_layers": {
          "min_val": 3,
          "max_val": 20
        }
      },
      "hints": [
        "Create a PyTorch module by inheriting from torch.nn.Module",
        "Initialize layers in __init__ with the specified hidden_size",
        "Use Xavier initialization with torch.nn.init.xavier_normal_ for weights",
        "Initialize biases to zero with torch.nn.init.zeros_",
        "In the forward method, process inputs with torch.cat to combine x, y, and t",
        "Apply tanh activation to all layers except the output layer",
        "Split the output tensor into u, v, and p components"
      ]
    },
    "exercise_8": {
      "answers": {
        "f_u_shape": {
          "shape": [5, 1]
        },
        "f_v_shape": {
          "shape": [5, 1]
        },
        "f_c_shape": {
          "shape": [5, 1]
        },
        "has_gradients": {
          "expected": true
        }
      },
      "hints": [
        "Enable gradients for x, y, and t with requires_grad_(True)",
        "Use torch.autograd.grad() to compute derivatives",
        "Set create_graph=True to enable higher-order derivatives",
        "For first derivatives, differentiate with respect to x, y, or t",
        "For second derivatives, differentiate the first derivatives",
        "Compute the Navier-Stokes residuals using the model's viscosity (nu)",
        "Check that residuals have the same shape as the inputs"
      ]
    },
    "exercise_9": {
      "answers": {
        "function_code": {
          "contains": [
            "def train_pinn",
            "Adam",
            "LBFGS",
            "closure",
            "data_loss",
            "physics_loss",
            "backward()",
            "step()"
          ]
        },
        "has_adam": {
          "expected": true
        },
        "has_lbfgs": {
          "expected": true
        },
        "uses_closure": {
          "expected": true
        },
        "has_data_loss": {
          "expected": true
        },
        "has_physics_loss": {
          "expected": true
        },
        "computes_residuals": {
          "expected": true
        },
        "updates_weights": {
          "expected": true
        },
        "uses_backpropagation": {
          "expected": true
        },
        "learning_rate": {
          "min_val": 0.0001,
          "max_val": 0.01
        },
        "optimizer_params": {
          "has_max_iter": {
            "expected": true
          },
          "has_line_search": {
            "expected": true
          }
        }
      },
      "hints": [
        "Define a closure function that computes loss and gradients",
        "Use torch.optim.Adam for the first phase of training",
        "Use torch.optim.LBFGS for the second phase with appropriate parameters",
        "Compute data loss using MSE between predictions and true values",
        "Compute physics loss using the residuals from compute_ns_residuals",
        "Combine data loss and physics loss for the total loss",
        "Track progress using tqdm to display the loss during training",
        "Make sure to zero gradients before computing loss",
        "Remember to call backward() to compute gradients",
        "Set appropriate max_iter and line_search_fn parameters for LBFGS",
        "Use a learning rate between 0.0001 and 0.01 for Adam optimizer"
      ]
    },
    "exercise_10": {
      "answers": {
        "u_pred_shape": {
          "shape": [-1, -1]
        },
        "v_pred_shape": {
          "shape": [-1, -1]
        },
        "p_pred_shape": {
          "shape": [-1, -1]
        },
        "requires_grad_used": {
          "expected": true
        }
      },
      "hints": [
        "Set the model to evaluation mode with model.eval()",
        "Create input tensors with requires_grad=True for prediction",
        "Use torch.enable_grad() to temporarily enable gradients during prediction",
        "Append predictions to lists and then stack with np.stack()",
        "Make sure predictions have the shape (N, T) where N is the number of spatial points and T is the number of time steps",
        "Use detach() and cpu().numpy() to convert tensors to arrays",
        "Make ground truth data match the same shape as predictions"
      ]
    }
  },
  "SE04": {
    "exercise_1": {
      "answers": {
        "output1": {
          "expected": 26,
          "tolerance": 0
        },
        "output2": {
          "expected": 224,
          "tolerance": 0
        },
        "output3": {
          "expected": 64,
          "tolerance": 0
        },
        "output4": {
          "expected": 32,
          "tolerance": 0
        }
      },
      "hints": [
        "Remember the formula for output size: ((W - K + 2P) / S) + 1",
        "Check that your kernel shape and padding are correctly defined"
      ]
    },
    "exercise_2": {
      "answers": {
        "edge_detection_kernel": {
          "value": [
            [1, 0, -1],
            [0, 0, 0],
            [-1, 0, 1]
          ],
          "dtype": "numpy.ndarray",
          "shape": [3, 3]
        },
        "sharpen_kernel": {
          "value": [
            [0, -1, 0],
            [-1, 5, -1],
            [0, -1, 0]
          ],
          "dtype": "numpy.ndarray",
          "shape": [3, 3]
        },
        "emboss_kernel": {
          "value": [
            [-2, -1, 0],
            [-1, 1, 1],
            [0, 1, 2]
          ],
          "dtype": "numpy.ndarray",
          "shape": [3, 3]
        }
      },
      "hints": [
        "Make sure your edge detection kernel highlights boundaries between different regions",
        "The sharpening filter should enhance details by increasing contrast",
        "The embossing filter should create a 3D effect by highlighting edges with shadows",
        "Ensure your PyTorch convolution correctly applies the filter to each channel"
      ]
    },
    "exercise_3": {
      "answers": {
        "resize_transform": {
          "transform_type": "Compose",
          "contains": ["Resize", "ToTensor"],
          "resize_size": [128, 128]
        },
        "center_crop_transform": {
          "transform_type": "Compose",
          "contains": ["Resize", "CenterCrop", "ToTensor"],
          "crop_size": 100
        },
        "random_crop_transform": {
          "transform_type": "Compose",
          "contains": ["Resize", "RandomCrop", "ToTensor"],
          "crop_size": 100
        },
        "hflip_transform": {
          "transform_type": "Compose",
          "contains": ["Resize", "RandomHorizontalFlip", "ToTensor"],
          "flip_probability": 1.0
        },
        "rotate_transform": {
          "transform_type": "Compose",
          "contains": ["Resize", "RandomRotation", "ToTensor"],
          "rotation_degrees": 30
        },
        "color_transform": {
          "transform_type": "Compose",
          "contains": ["Resize", "ColorJitter", "ToTensor"],
          "brightness": {
            "min": 0.3,
            "max": 0.7
          },
          "contrast": {
            "min": 0.3,
            "max": 0.7
          }
        },
        "norm_transform": {
          "transform_type": "Compose",
          "contains": ["Resize", "ToTensor", "Normalize"],
          "norm_mean": [0.485, 0.456, 0.406],
          "norm_std": [0.229, 0.224, 0.225]
        }
      },
      "hints": [
        "Use transforms.RandomCrop(100) for random cropping",
        "Set p=1.0 in transforms.RandomHorizontalFlip for guaranteed flipping",
        "Use transforms.RandomRotation(degrees=30) for rotation",
        "The ColorJitter transformation should modify brightness, contrast, saturation, and hue",
        "ImageNet normalization uses mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]"
      ]
    },
    "exercise_4": {
      "answers": {
        "train_transforms": {
          "transform_type": "Compose",
          "contains": [
            "Resize",
            "RandomHorizontalFlip",
            "RandomRotation",
            "ColorJitter",
            "ToTensor",
            "Normalize"
          ],
          "normalization": {
            "mean": [0.485, 0.456, 0.406],
            "std": [0.229, 0.224, 0.225]
          }
        },
        "test_val_transforms": {
          "transform_type": "Compose",
          "contains": ["Resize", "ToTensor", "Normalize"],
          "normalization": {
            "mean": [0.485, 0.456, 0.406],
            "std": [0.229, 0.224, 0.225]
          }
        },
        "train_data": {
          "dataset_type": "ImageFolder",
          "classes": ["crack", "no_crack"],
          "transform_applied": true
        },
        "test_data": {
          "dataset_type": "ImageFolder",
          "classes": ["crack", "no_crack"],
          "transform_applied": true
        },
        "val_data": {
          "dataset_type": "ImageFolder",
          "classes": ["crack", "no_crack"],
          "transform_applied": true
        }
      },
      "hints": [
        "Use transforms.Normalize with ImageNet statistics",
        "Training transforms should include data augmentation methods",
        "Test/validation transforms should only include resize, ToTensor, and normalization",
        "Use ImageFolder with appropriate root directories and transforms"
      ]
    },
    "exercise_5": {
      "answers": {
        "train_dataloader": {
          "loader_type": "DataLoader",
          "batch_size": {
            "min": 8,
            "max": 128
          },
          "shuffle": true
        },
        "test_dataloader": {
          "loader_type": "DataLoader",
          "batch_size": {
            "min": 8,
            "max": 128
          },
          "shuffle": false
        },
        "val_dataloader": {
          "loader_type": "DataLoader",
          "batch_size": {
            "min": 8,
            "max": 128
          },
          "shuffle": false
        }
      },
      "hints": [
        "Use DataLoader with appropriate datasets",
        "Set shuffle=True for training data and shuffle=False for test/validation data",
        "Choose a reasonable batch size (16, 32, or 64)",
        "Monitor memory usage if using large batch sizes"
      ]
    },
    "exercise_6": {
      "answers": {
        "model_architecture": {
          "model_type": "nn.Module",
          "has_init": true,
          "has_forward": true
        },
        "conv_layer": {
          "layer_type": "Conv2d",
          "in_channels": 3,
          "out_channels": {
            "min": 8,
            "max": 64
          },
          "kernel_size": {
            "min": 2,
            "max": 7
          },
          "stride": {
            "min": 1,
            "max": 3
          },
          "padding": {
            "min": 0,
            "max": 3
          }
        },
        "linear_layers": {
          "count": {
            "min": 1,
            "max": 3
          },
          "output_features": 2
        },
        "activation": {
          "function": "ReLU",
          "count": {
            "min": 1,
            "max": 4
          }
        }
      },
      "hints": [
        "Use torch.nn.Conv2d for convolutional layers",
        "Make sure the input dimensions to the first linear layer match the output of the convolutional layer",
        "Use ReLU activation after the convolutional layer",
        "The output layer should have the number of classes as the output dimension"
      ]
    },
    "exercise_7": {
      "answers": {
        "test_accuracy": {
          "min_val": 0.5,
          "max_val": 1.0,
          "evaluation_mode": true
        },
        "classification_report": {
          "contains_metrics": ["precision", "recall", "f1-score", "support"],
          "classes": ["crack", "no_crack"],
          "f1_score": {
            "min": 0.4,
            "max": 1.0
          },
          "uses_utility_function": true
        }
      },
      "hints": [
        "Use utils.ml.compute_accuracy to calculate the accuracy",
        "Generate a classification report with utils.ml.compute_classification_report",
        "Pass the model, test dataloader, and class names to the functions"
      ]
    },
    "exercise_8": {
      "answers": {
        "model_architecture": {
          "model_type": "nn.Module",
          "has_init": true,
          "has_forward": true,
          "layers_count": {
            "min": 6,
            "max": 15
          }
        },
        "conv_layers": {
          "count": {
            "min": 2,
            "max": 5
          },
          "channels": {
            "first_layer": {
              "in": 3,
              "out": {
                "min": 8,
                "max": 64
              }
            },
            "increasing_pattern": true
          },
          "kernel_sizes": {
            "min": 2,
            "max": 7
          }
        },
        "pooling_layers": {
          "count": {
            "min": 1,
            "max": 4
          },
          "type": "MaxPool2d",
          "kernel_size": {
            "min": 2,
            "max": 3
          },
          "stride": {
            "min": 1,
            "max": 3
          }
        },
        "batch_norm_layers": {
          "present": true,
          "count": {
            "min": 1,
            "max": 5
          },
          "momentum": {
            "min": 0.1,
            "max": 0.9
          }
        },
        "dropout_layers": {
          "present": true,
          "count": {
            "min": 1,
            "max": 3
          },
          "rate": {
            "min": 0.05,
            "max": 0.5
          }
        },
        "flatten_operation": {
          "present": true,
          "correct_dimensions": true
        }
      },
      "hints": [
        "Use torch.nn.Conv2d for convolutional layers",
        "Add torch.nn.MaxPool2d after convolutional layers",
        "Use torch.nn.BatchNorm2d for batch normalization",
        "Add dropout layers for regularization",
        "Make sure to flatten the output before the fully connected layers",
        "Check the input dimensions to the first linear layer based on the size reduction from pooling layers"
      ]
    },
    "exercise_9": {
      "answers": {
        "test_accuracy": {
          "min_val": 0.75,
          "max_val": 1.0,
          "improvement": {
            "min": 0.05,
            "max": 1.0
          },
          "evaluation_mode": true,
          "no_grad": true
        },
        "classification_report": {
          "contains_metrics": ["precision", "recall", "f1-score", "support"],
          "classes": ["crack", "no_crack"],
          "precision": {
            "min": 0.6,
            "max": 1.0
          },
          "recall": {
            "min": 0.6,
            "max": 1.0
          },
          "f1_score": {
            "min": 0.6,
            "max": 1.0
          },
          "uses_utility_function": true,
          "balanced_performance": true
        }
      },
      "hints": [
        "Use utils.ml.compute_accuracy to calculate the accuracy",
        "Generate a classification report with utils.ml.compute_classification_report",
        "The VGG architecture should outperform the simple CNN model from Exercise 6"
      ]
    }
  },
  "SE05": {
    "exercise_1": {
      "answers": {
        "has_getitem": {
          "expected": true
        },
        "has_len": {
          "expected": true
        },
        "dataset_instance": {
          "check_type": "instance",
          "expected_class": "ISICDataset"
        },
        "img_transform_used": {
          "expected": true
        },
        "mask_transform_used": {
          "expected": true
        }
      },
      "hints": [
        "Make sure to implement both __getitem__ and __len__ methods in your custom dataset class",
        "Your dataset class should accept image_dir, mask_dir, img_transform and mask_transform parameters",
        "Remember to convert the image to RGB and the mask to grayscale",
        "Apply img_transform to the image and mask_transform to the mask if provided"
      ]
    },
    "exercise_2": {
      "answers": {
        "dataloader": {
          "check_type": "instance",
          "expected_class": "DataLoader"
        },
        "mean_shape": {
          "expected": [3],
          "check_type": "shape"
        },
        "std_shape": {
          "expected": [3],
          "check_type": "shape"
        },
        "mean_range": {
          "expected": true,
          "check_type": "boolean"
        },
        "std_range": {
          "expected": true,
          "check_type": "boolean"
        }
      },
      "hints": [
        "Calculate channel_sum and channel_squared_sum across the dataset",
        "Normalize by the total number of pixels (n_pixels)",
        "The mean should be between 0 and 1 for normalized images",
        "The std should be positive and less than 1"
      ]
    },
    "exercise_3": {
      "answers": {
        "train_transforms": {
          "check_type": "instance",
          "expected_class": "Compose"
        },
        "valid_transforms": {
          "check_type": "instance",
          "expected_class": "Compose"
        },
        "has_resize": {
          "expected": true
        },
        "has_horizontal_flip": {
          "expected": true
        },
        "has_vertical_flip": {
          "expected": true
        },
        "has_rotation": {
          "expected": true
        },
        "has_color_jitter": {
          "expected": true
        },
        "has_normalize": {
          "expected": true
        },
        "has_to_tensor": {
          "expected": true
        }
      },
      "hints": [
        "Use albumentations.Compose to combine multiple transformations",
        "Include albumentations.Resize to resize images to 64x64",
        "Add flip and rotation augmentations for training data",
        "Include albumentations.Normalize with the calculated mean and std",
        "End with ToTensorV2 transformation to convert to PyTorch tensors"
      ]
    },
    "exercise_4": {
      "answers": {
        "inherits_from_isic": {
          "expected": true
        },
        "has_getitem_override": {
          "expected": true
        },
        "uses_numpy": {
          "expected": true
        },
        "normalizes_mask": {
          "expected": true
        },
        "ensures_binary": {
          "expected": true
        }
      },
      "hints": [
        "Make your ISICDatasetAlbumentations class inherit from ISICDataset",
        "Override the __getitem__ method to use albumentations",
        "Convert PIL Images to numpy arrays before applying albumentations",
        "Normalize mask values to be between 0 and 1",
        "Ensure the mask is binary (0 or 1) using a threshold of 0.5"
      ]
    },
    "exercise_5": {
      "answers": {
        "train_dataset": {
          "check_type": "instance",
          "expected_class": "Subset"
        },
        "valid_dataset": {
          "check_type": "instance",
          "expected_class": "Subset"
        },
        "train_dataloader": {
          "check_type": "instance",
          "expected_class": "DataLoader"
        },
        "valid_dataloader": {
          "check_type": "instance",
          "expected_class": "DataLoader"
        },
        "train_split_ratio": {
          "expected": 0.8,
          "tolerance": 0.05
        },
        "batch_size_correct": {
          "expected": true
        }
      },
      "hints": [
        "Use torch.utils.data.random_split to split the dataset into training and validation sets",
        "Use an 80/20 split for training and validation",
        "Create DataLoader objects with batch_size=16",
        "Set shuffle=True for the training DataLoader",
        "Set shuffle=False for the validation DataLoader"
      ]
    },
    "exercise_6": {
      "answers": {
        "has_forward": {
          "expected": true
        },
        "has_two_conv_layers": {
          "expected": true
        },
        "has_batch_norm": {
          "expected": true
        },
        "has_relu": {
          "expected": true
        },
        "uses_sequential": {
          "expected": true
        }
      },
      "hints": [
        "Create a DoubleConv class that inherits from torch.nn.Module",
        "Use torch.nn.Sequential to combine the layers",
        "Include two Conv2d layers with kernel_size=3 and padding=1",
        "Add BatchNorm2d after each Conv2d layer",
        "Use ReLU activation after each BatchNorm2d",
        "Implement the forward method to process the input through the sequential layers"
      ]
    },
    "exercise_7": {
      "answers": {
        "has_forward": {
          "expected": true
        },
        "has_maxpool": {
          "expected": true
        },
        "uses_doubleconv": {
          "expected": true
        },
        "uses_sequential": {
          "expected": true
        }
      },
      "hints": [
        "Create a class that inherits from nn.Module",
        "Use nn.Sequential to combine a MaxPool2d with the DoubleConv",
        "Set kernel_size=2 for the MaxPool2d layer",
        "Implement the forward method to pass input through the sequential layers"
      ]
    },
    "exercise_8": {
      "answers": {
        "has_forward": {
          "expected": true
        },
        "has_transpose_conv": {
          "expected": true
        },
        "uses_doubleconv": {
          "expected": true
        },
        "handles_size_mismatch": {
          "expected": true
        },
        "uses_concat": {
          "expected": true
        }
      },
      "hints": [
        "Create a class that inherits from nn.Module",
        "Use nn.ConvTranspose2d for upsampling with kernel_size=2 and stride=2",
        "Check for size mismatches between upsampled and skip connection tensors",
        "Use torch.cat() to concatenate upsampled and skip connection tensors along dimension 1",
        "Pass the concatenated tensor through the DoubleConv"
      ]
    },
    "exercise_9": {
      "answers": {
        "has_forward": {
          "expected": true
        },
        "has_encoder_path": {
          "expected": true
        },
        "has_decoder_path": {
          "expected": true
        },
        "has_final_conv": {
          "expected": true
        },
        "uses_sigmoid": {
          "expected": true
        }
      },
      "hints": [
        "Create a class that inherits from nn.Module",
        "Define encoder path using DoubleConv and Down classes",
        "Define decoder path using Up class with skip connections",
        "Use nn.Conv2d with kernel_size=1 for final output layer",
        "Apply sigmoid activation to the output for binary segmentation",
        "Pass skip connection outputs from encoder to decoder in reverse order"
      ]
    },
    "exercise_10": {
      "answers": {
        "has_forward": {
          "expected": true
        },
        "handles_flattening": {
          "expected": true
        },
        "calculates_intersection": {
          "expected": true
        },
        "uses_smoothing": {
          "expected": true
        },
        "returns_1_minus_dice": {
          "expected": true
        }
      },
      "hints": [
        "Create a class that inherits from nn.Module",
        "Flatten inputs using view(-1) to ensure proper calculation",
        "Calculate intersection as the product sum of predictions and ground truth",
        "Add a smoothing factor to prevent division by zero",
        "Return 1 minus the Dice coefficient as the loss value",
        "Use torch.clamp to ensure loss stays in valid range"
      ]
    }
  }
}
